{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14818149505182915980\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3141979340\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1032192470647457328\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Checking to see if gpu is connected correctly\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "input_dim = 28 * 28 # pixel length and width of each image\n",
    "output_dim = nb_classes = 10\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "x_train = x_train.reshape(60000, input_dim)\n",
    "x_test = x_test.reshape(10000, input_dim)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 # normalize by dividing by maximum pixel value\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, nb_classes)\n",
    "y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_of_first = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(x_train[123].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[123]))\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.imshow(x_train[124].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[124]))\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.imshow(x_train[125].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[125]))\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.imshow(x_train[126].reshape(28,28), cmap=\"gray\")\n",
    "plt.title(\"Label of the image: {}\".format(y_train[126]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028, input_shape=shape_of_first, activation=\"relu\"))\n",
    "model.add(Dense(1028, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1028)              806980    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1028)              1057812   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                10290     \n",
      "=================================================================\n",
      "Total params: 1,875,082\n",
      "Trainable params: 1,875,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016370DD3F78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016370DD3F78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "Executing op __inference_initialize_variables_36071 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_distributed_function_36336 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9981Executing op __inference_distributed_function_37856 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.2608 - val_accuracy: 0.9824\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.2371 - val_accuracy: 0.9813\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.2979 - val_accuracy: 0.9824\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.2180 - val_accuracy: 0.9843\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.2892 - val_accuracy: 0.9817\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.2523 - val_accuracy: 0.9843\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.2706 - val_accuracy: 0.9830\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.2448 - val_accuracy: 0.9844\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.3513 - val_accuracy: 0.9784\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.2668 - val_accuracy: 0.9840\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.3361 - val_accuracy: 0.9807\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.3417 - val_accuracy: 0.9812\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.3322 - val_accuracy: 0.9826\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.3201 - val_accuracy: 0.9803\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.2557 - val_accuracy: 0.9842\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.2627 - val_accuracy: 0.9852\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.3118 - val_accuracy: 0.9812\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2824 - val_accuracy: 0.9841\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.2954 - val_accuracy: 0.9821\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3408 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16420a404c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimzer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=20, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this task, you'll build an ANN and train and test it using the MNIST data. This ANN should consist of two hidden and one output layer. All hidden layers should be dense. The neuron sizes of the first layer and the second layer should be 32 and 16 respectively. Train this model 20 epochs and compare your train and test set performance with the example above Is there any difference? If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "new_model = Sequential()\n",
    "model.add(Dense(1028, input_shape=shape_of_first, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016420BA5A68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016420BA5A68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "Executing op __inference_initialize_variables_70193 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_distributed_function_70437 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 2.3009 - accuracy: 0.1162Executing op __inference_distributed_function_71985 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 2.3009 - accuracy: 0.1162 - val_loss: 2.2994 - val_accuracy: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2983 - accuracy: 0.1124 - val_loss: 2.2964 - val_accuracy: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 2.2936 - accuracy: 0.1259 - val_loss: 2.2890 - val_accuracy: 0.1401\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2799 - accuracy: 0.1925 - val_loss: 2.2642 - val_accuracy: 0.2146\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2155 - accuracy: 0.2363 - val_loss: 2.1265 - val_accuracy: 0.2439\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.9759 - accuracy: 0.2257 - val_loss: 1.8426 - val_accuracy: 0.2273\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 1.7650 - accuracy: 0.2608 - val_loss: 1.6957 - val_accuracy: 0.3112\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.6206 - accuracy: 0.3376 - val_loss: 1.5351 - val_accuracy: 0.3824\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 1.4687 - accuracy: 0.3988 - val_loss: 1.3690 - val_accuracy: 0.4696\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 1.3250 - accuracy: 0.4817 - val_loss: 1.3074 - val_accuracy: 0.4754\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 1.1540 - accuracy: 0.5867 - val_loss: 1.0197 - val_accuracy: 0.7034\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.9180 - accuracy: 0.7349 - val_loss: 0.7519 - val_accuracy: 0.8209\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.6704 - accuracy: 0.8328 - val_loss: 0.5657 - val_accuracy: 0.8732\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.5038 - accuracy: 0.8820 - val_loss: 0.4674 - val_accuracy: 0.8958\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.4141 - accuracy: 0.9023 - val_loss: 0.4025 - val_accuracy: 0.9117\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3528 - accuracy: 0.9174 - val_loss: 0.4430 - val_accuracy: 0.9017\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3048 - accuracy: 0.9286 - val_loss: 0.4432 - val_accuracy: 0.8884\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2638 - accuracy: 0.9384 - val_loss: 0.3147 - val_accuracy: 0.9301\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2357 - accuracy: 0.9445 - val_loss: 0.3268 - val_accuracy: 0.9272\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2261 - accuracy: 0.9462 - val_loss: 0.3112 - val_accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x164234bbf48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=20, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this model to the previous, it appears as though having more nodes available in the hidden layers performed better overall to having significantly less nodes but more hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You'll also build an ANN in this task. This time, this ANN should have 5 hidden layers and 1 output layer. All the layers should be dense. The neuron numbers for the hidden layers should be 1024, 512, 256, 128 and 64. Train this model 20 epochs and test it using the same data from the previous task and compare your results. Is there any difference? If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016423DD03A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000016423DD03A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "Executing op __inference_initialize_variables_104254 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_distributed_function_104494 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "58496/60000 [============================>.] - ETA: 0s - loss: 1.4129 - accuracy: 0.5838Executing op __inference_distributed_function_106042 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 1.3899 - accuracy: 0.5908 - val_loss: 0.4535 - val_accuracy: 0.8751\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.89 - 2s 39us/sample - loss: 0.3804 - accuracy: 0.8910 - val_loss: 0.3047 - val_accuracy: 0.9110\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2803 - accuracy: 0.9187 - val_loss: 0.2441 - val_accuracy: 0.9286\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2293 - accuracy: 0.9331 - val_loss: 0.2117 - val_accuracy: 0.9359\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1928 - accuracy: 0.9441 - val_loss: 0.1770 - val_accuracy: 0.9478\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1657 - accuracy: 0.9517 - val_loss: 0.1621 - val_accuracy: 0.9504\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1443 - accuracy: 0.9579 - val_loss: 0.1460 - val_accuracy: 0.9540\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1279 - accuracy: 0.9627 - val_loss: 0.1307 - val_accuracy: 0.9590\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1143 - accuracy: 0.9664 - val_loss: 0.1214 - val_accuracy: 0.9631\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1026 - accuracy: 0.9708 - val_loss: 0.1203 - val_accuracy: 0.9640\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0923 - accuracy: 0.9735 - val_loss: 0.1031 - val_accuracy: 0.9682\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0842 - accuracy: 0.9753 - val_loss: 0.0955 - val_accuracy: 0.9696\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0762 - accuracy: 0.9785 - val_loss: 0.0987 - val_accuracy: 0.9682\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0685 - accuracy: 0.9808 - val_loss: 0.0884 - val_accuracy: 0.9707\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.98 - 2s 37us/sample - loss: 0.0632 - accuracy: 0.9819 - val_loss: 0.0910 - val_accuracy: 0.9697\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.98 - 2s 35us/sample - loss: 0.0570 - accuracy: 0.9837 - val_loss: 0.0915 - val_accuracy: 0.9708\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0524 - accuracy: 0.9855 - val_loss: 0.0828 - val_accuracy: 0.9735\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0478 - accuracy: 0.9866 - val_loss: 0.0965 - val_accuracy: 0.9691\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0427 - accuracy: 0.9886 - val_loss: 0.0805 - val_accuracy: 0.9733\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0396 - accuracy: 0.9895 - val_loss: 0.0772 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16423dca1c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028, input_shape=shape_of_first, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=20, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is the best suited of the three models and combines the better qualities of the previous two to optimize the accuracy while reducing overfitting of the training data. It uses both a sufficient number of nodes to find patterns within discreet pixel clusters, and sufficient layers to find associations between those patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
